---
layout: "docs"
page_title: "Jepsen Testing"
sidebar_current: "docs-internals-jepsen"
description: |-
  FIXME Don't remove this and create a description until all other FIXME and TODO are fixmed and todone
  TODO Port every code link to commits rather than linking to github master :'(
---

# FIXME(content) Jepsen Testing

## FIXME(content) Intoduction
  NOTE This is probably better in just the blog post. Documents have a different voice, I believe.
  I'm a contributing author for [Jepsen](https://jepsen.io) and a major contributor to both the [Jepsen library](https://github.com/jepsen-io/jepsen) and the [Knossos linearizability checker](https://github.com/jepsen-io/knossos). In December of 2019, I joined the Consul Core team as a Senior Software Engineer to build and rigoriously verify all of that networked, distributed goodness.

TODO
- Why do we revisit Hashicorp Consul tests?
  - In this blog post, we're going to explore Consul's Jepsen test suite and recent work to improve it.
  - What is consul?
    - FIXME
    - Consul is a coordination store and servicy discovery system.
      - As such it's a large distributed system, communicating critical operations over a network.
    - And it's well understood that [networks are not reliable](https://aphyr.com/posts/288-the-network-is-reliable) and distributed systems are [notoriously difficult to implement correctly]().
    - (REVIEW: FACT CHECK PLEASE) Consul is expected to be run datacenters with a quorum of 3 to 5 nodes, each node running many concurrent parts within. That's a large surface area for unexpected behavior to occur.
    - Consul uses raft to solve the problem of coordination
  - What are its [Raft-based consensus system](https://www.consul.io/docs/internals/consensus.html) features
    -  REVIEW What features are built on top of it? (Key value store, locks, txns?)
    - the jepsen testing one of the foundations of Consul: its strongly consistent storage layer: Raft.
    - Consul uses a combination of raft, serf.
  - Why do Jepsen tests?
    - [Consul's jepsen suite](https://github.com/jepsen-io/jepsen/tree/master/consul),
    - Jepsen testing is a lot like security testing. Only, instead of testing a system against a malicious actor, you test it against environmental factors that are otherwise difficult to test for.
    - To do so, we test an actual running system by generating load while injecting faults at a system (clocks), network (partitions), process(pause, kill, restart), and application (membership change) levels.
    - This makes jepsen testing complementary to practices like unit and integration testing.

  We'll explain what Jepsen testing is all about, how the Consul team has tested Consul using the Jepsen library before, how the tests work, what's new, how Consul has fared given the update, and what future work remains.

  It's important to note that, while I have worked with database vendors and Jepsen, LLC as an indepedent researcher, and [published a formal Jepsen analysis](http://jepsen.io/analyses/mongodb-3-6-4), this is **NOT** an offical Jepsen report. Jepsen reports for distributed systems are performed as an indepedent entity, in accordance with the Jepsen Ethics Policy, and verified by Kyle Kingbury. Though I have adhered to the ethics policy, as an employee of HashiCorp I have a clear conflict of interest. Therefore, readers of this article **must not** consider this a substitute for an offical Jepsen [analysis](http://jepsen.io/analyses).

## FIXME(content) What is Jepsen testing?
  [Jepsen](http://jepsen.io/#about-jepsen) testing started back in 2013 (?) to test the reliability of distributed systems and strongly influenced popular databases in use today. (TODO How? MongoDB, Elasticsearch, etc.) It started as a [testing library](https://github.com/jepsen-io/jepsen) by Kyle Kingsbury to test that the behavior of distributed systems, for example: databases, queues, locking services, consensus systems, etc., match the expectations vendors offer to their users in documentation and promotional material.  Especially under load and the kinds of adverse conditions (like network partitions, system clock instability, and unexpected changes in cluster membership) that were known to occur (TODO Link to Peter Bailis article) but for which testing options lacked at the time. Over the years, Jepsen has grown into an LLC offering indepedent research and training, and as a destination for readers to understand distributed systems in use today through their portfolio of [analyses](http://jepsen.io/analyses), and learn more about their properties through resources like [talks](http://jepsen.io/talks) and articles on the field of distributed systems verification, such as the [consistency graph and explanations](http://jepsen.io/consistency).

  Jepsen testing matters, because it means that databases keep the promises about the behavior of their databases that they make to their users.

## FIXME(content) Consul's Jepsen Tests
### FIXME(content) History
  Five and a half years ago, the early Consul team did a rare thing in the industry at the time: they elected to write their own Jepsen tests and . Even rarer, their results turned out pretty well! Adding consistency levels (todo link to docs mentioned in the blog post)
    - [Test and results](https://aphyr.com/posts/316-call-me-maybe-etcd-and-consul)
  - Previous version of the docs (maybe move them to a new page, link to it in the new release post)
  - 5.5 years ago X and Y set out to write their own Jepsen tests -- very rare for the time. Their results turned out pretty well! Adding consistency levels (todo link to docs mentioned in the blog post)

### FIXME(content) How does a Jepsen test work?
#### FIXME From the Top

- Jepsen components are defined on the test map
  - Create `generator` as a stateful fn that produces `ops`
  - Create `nemeses` as a special kind of client that creates some kind of effect on the node
  - Setup `dbs` on the nodes
  - Select a workload and merge it into the test map
    - A `generator` is a stateful function that returns `op` invocations.
      - The test ends when a `generator` finishes producing ops
      - Generators can be configured in many ways, e.x. with time limits, with specific orders for operations, and more.
    - Open `clients` on the nodes.
      - A client is a [database and test-specific implementation](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul/register.clj#L16) that knows how to take an invocation and apply it to a database, recording the database's response as a completion `{:ok, :fail, :info}`
      - We will also often implement a `jepsen.{test}.client` namespace for shared functions between client implementations for different tests/workloads. This allows us to write clients within a test suite that can interpret different kinds of invocations, while sharing network APIs, synchronization functions, and error-interpretation code.
    - Contains a `checker`
  - Open `clients` on the nodes
  - `Clients` consume the genned `ops`
  - `Clients` applying each `op` as an `invoke` record their result as a completion `{:ok, :fail, :info}`
  - These invocations and completions are written to a log called a `history`
  - The `history` is then given to various `checkers` to make `valid`, `invalid`, or `indeterminate` assertions about the history

- TODO Fig. 1, Network diagram of a jepsen test in action. Control node, and 5 db nodes, each node containing a `client` and `consul agent` (running as a server)
  - Include partitions. (you can key off of some stuff from the mongodb analysis here). To show what a running test looks like.
  - Note that the connection from the control node to each jepsen `client` is not affected by the partition nemesis. Crucially, this allow us to apply operations even while iptables config denies traffic between the db nodes.

- TODO Test lifecycle Describe the test runner and the workloads?
  - Here are all the steps in order
    - Test runner builds the test map containing the components above
    - Setup `dbs` on the nodes
    - Create `nemeses` as a special kind of client that creates some kind of effect on the node
    - Picks a workload
      - Workloads abstract over the 3 components that are different between jepsen test kinds. `generator`s, `client`s, and `checker`s.
    - Test start
    - `Clients` consume the genned `ops`
    - `Clients` applying each `op` as an `invoke` record their result as a completion `{:ok, :fail, :info}`
    - These invocations and completions are written to a log called a `history`
    - The `history` is then given to various `checkers` to make `valid`, `invalid`, or `indeterminate` assertions about the history

#### FIXME(content!) What is a Register test?
  -  ops that clients know how to handle. This appends into our `history`, and then we pass the history to our linear `checker`, [Knossos](https://github.com/jepsen-io/knossos) which ensures the keys are linearizable.
  - TODO Diagram of an independent register.
  - TODO Diagram of what a nonlinearizable result looks like (can use an example out of linear.png?)

#### FIXME(proofing) What did we change?
First and foremost, after five and a half years, the old test suite got a bit dusty and didn't run anymore. So, we started by bumping the test version up to [Jepsen v0.1.15](https://github.com/jepsen-io/jepsen/blob/master/consul/project.clj#L7). We rewrote the test runner to accept a spec of [CLI args](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul.clj#L58) and we can now implement tests (like register) as [workloads](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul.clj#L15). Workloads allow us to run sets of tests at once (or no tests at all) by specifying which, e.g. `--workload register`. This is useful in all contexts of running and developing a test suite. We also paramaterized [different release versions of Consul](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul/db.clj#L58) All of the tests for this post were run against [Consul v1.6.1](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul.clj#L61).

Once we'd upgraded the structure of the tests to fit jepsen's newer abstractions, we double checked all the behavior of the previous register test implementation. While most of the previous tests were still valid, we found a various places to improve the stictness of the tests. First, we fixed a [bug](https://github.com/jepsen-io/jepsen/commit/db24fac7c68c3283b9c2c20e742fa508268ab07e#diff-f5e04f13dad45e9e80332ddce9d754e8R57) with the register test's `client` that prevented CAS (compare-and-swap) operations from ever being completed. We also ported the register test's generator to [jepsen.independent/concurrent-generator](https://github.com/jepsen-io/jepsen/commit/19b085f49471abffb57fa240021a15640d0005a5#diff-71833489f38c369aa9ca5454002fe061R64) to raise the thoughput significantly by writing to [multiple keys in parallel](http://jepsen-io.github.io/jepsen/jepsen.independent.html#var-concurrent-generator) with 10 threads per key. This also speeds up and reduces the memory footprint of the checker by subdividing the state space that [Knossos' two competing implementations](https://github.com/jepsen-io/knossos/blob/master/src/knossos/competition.clj#L18-L19) have to explore. Linearizability checking is NP-hard as is, so we can't catch every possible violation every time. In practice, however, violations over very long time periods are reare, and and various tradeoffs are taken into account to make linear checking practical.

## FIXME Outcomes
### FIXME(content!) Results
Based on weeks of testing against the updated register workload, we're happy to announce that Consul continues to pass its jepsen test suite! While there's certainly more workloads besides the register  to explore (see Future Work below), after five and a half years and a much higher throughput, stricter test, Consul appears to continue to implement hashicorp/Raft correctly. TODO (double check this) There are also no known consistency issues with Consul's consensus system or hashicorp/raft at this time.
```
Everything looks good! ヽ(‘ー`)ノ
```
(Well, at least everything we've checked so far!)

- TODO Include images/embeds of individual test results, with rate and latency graphsj
- TODO S3 downloads for sets of test results

- TODO Double check that we're configured for strong consistency If so, check behavior without strong consistency enabled as a control

### FIXME(proofing) Future Work
- This has been a side project and no additional work is scheduled yet, but there is much more work we can do to more strictly verify Consul and other HashiCorp products, such as Vault and Nomad, that utilize consensus. There are more [tests](https://github.com/jepsen-io/jepsen/tree/master/jepsen/src/jepsen/tests) that we can implement as additional workloads. For example, append-only set tests are quick and simple to verify broad regressions when run in CI. While more strict tests like [lock](https://github.com/jepsen-io/etcd/blob/master/src/jepsen/etcd/lock.clj), [bank](https://github.com/jepsen-io/jepsen/blob/master/jepsen/src/jepsen/tests/bank.clj), [cycle](https://github.com/jepsen-io/jepsen/blob/master/jepsen/src/jepsen/tests/cycle.clj), [causal-reverse](https://github.com/jepsen-io/jepsen/blob/master/jepsen/src/jepsen/tests/causal_reverse.clj) (and more!) tests can check additional behavior in Consul that we haven't yet explored and verified in our Jepsen suite.

In addition to more workloads, there are more [nemeses than network partitions](https://github.com/jepsen-io/etcd/blob/master/src/jepsen/etcd/nemesis.clj) that we can bring in and compose into nemesis packages. There exist nemeses that can pause, kill, and restart consul processes, induce membership changes and pathologically alter system clocks.

Also, we may yet find bugs by exploring the large state space of Consul's configuration options. Right now, we test Consul under [default paramters](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul/db.clj#L31) doing very little besides starting an agent as a server. With options for users to adjust timeouts and various other paramters, there's lots more for the Consul Core team to explore, verify, and document. In the future, we may [construct a config.hcl file from CLI params](https://github.com/jepsen-io/jepsen/blob/master/consul/src/jepsen/consul/db.clj#L65) exposing more configuration options to the jepsen test suite.

   In addition to enhancements to the test suite itself, there's the possibility to integrate Jepsen tests more closely in Consul's development workflow via our continuous integration (CI) pipeline. Other database vendors run their jepsen suites nightly and/or weekly to look for regressions in the primary working branch. As we add more workloads of varying complexity and strictness, we can tune how often these run. (Waiting for a full linear test every single commit is not necessarily practical.) As we expand our testing practices to test backwards compatability, TODO (envoy, vault) we can test mulitple releases of Consul itself now that we've parameterized the version of Consul we download.

  Finally, there's been some discussion of testing other HashiCorp products' use of Raft, e.g. Nomad and Vault's. Linearizable systems are not guaranteed to compose, so it's important to test both the library itself (Raft) and a system's usage of Raft.

## FIXME(content) Conclusion
  NOTE This is probably better in just the blog post. Documents have a different voice, I believe.
  As you can see, there's lots to be excited about with Jepsen testing and Consul. We hope you've learned a lot about verifying distributed systems, and piqued your interest for both Consul and other HashiCorp products. FIXME This feels super canned

### Additional reading
Caitie McCaffrey's "The Verification of a Distributed System" provides an excellent view of the many techniques involved in dist. sys. verification, and can be a great next step for those interested in testing their own services.
https://queue.acm.org/detail.cfm?id=2889274
