---
layout: docs
page_title: Service Mesh Observability - Consul Dataplane Dashboard
description: >-
  This documentation provides an overview of the Consul Dataplane dashboard.
---

# Dashboard for Consul dataplane metrics

This page provides reference information about the Grafana dashboard configuration included in [this GitHub repository](https://github.com/YasminLorinKaygalak/GrafanaDemo/tree/main). The Consul dataplane dashboard provides a comprehensive view of the service health, performance, and resource utilization within the Consul service mesh. 

You can monitor key metrics at both the cluster and service levels with this dashboard. It can help you ensure service reliability and performance.

## Consul dataplane metrics

The Consul dataplane dashboard provides the following information about service mesh operations.

### Live Servers
- **Metric:** `sum(envoy_server_live{app=~"$service"})`
- **Description:** This metric displays the number of live Envoy proxies currently running within the service mesh. It helps operators track the availability of services and identify any outages or issues with the service mesh components.

### Total Request Success Rate
- **Metric:** `sum(irate(envoy_cluster_upstream_rq_xx{...}[10m]))`
- **Description:** This metric tracks the percentage of successful requests across the service mesh. It excludes 4xx and 5xx response codes to focus on operational success, helping operators monitor overall service reliability.

### Total Failed Requests
- **Metric:** `sum(increase(envoy_cluster_upstream_rq_xx{...}[10m]))`
- **Description:** This pie chart shows the total number of failed requests within the service mesh, categorized by service. It provides a visual breakdown of where failures are occurring, allowing operators to focus on problematic services.

### Requests Per Second
- **Metric:** `sum(rate(envoy_http_downstream_rq_total{...}[5m]))`
- **Description:** This metric shows the rate of incoming HTTP requests per second to the selected services. It helps operators understand the current load on services and how much traffic they are processing.

### Unhealthy Clusters
- **Metric:** `(sum(envoy_cluster_membership_healthy{...}) - sum(envoy_cluster_membership_total{...}))`
- **Description:** This metric tracks the number of unhealthy clusters in the mesh, helping operators identify services that are experiencing issues and need attention to ensure operational health.

### Heap Size
- **Metric:** `SUM(envoy_server_memory_heap_size{app=~"$service"})`
- **Description:** This metric displays the total memory heap size of the Envoy proxies. Monitoring heap size is essential to detect memory issues and ensure that services are operating efficiently.

### Allocated Memory
- **Metric:** `SUM(envoy_server_memory_allocated{app=~"$service"})`
- **Description:** This metric shows the amount of memory allocated by the Envoy proxies. It helps operators monitor the resource usage of services to prevent memory overuse and optimize performance.

### Avg Uptime Per Node
- **Metric:** `avg(envoy_server_uptime{app=~"$service"})`
- **Description:** This metric calculates the average uptime of Envoy proxies across all nodes. It helps operators monitor the stability of services and detect potential issues with service restarts or crashes.

### Cluster State
- **Metric:** `(sum(envoy_cluster_membership_total{...}) - sum(envoy_cluster_membership_healthy{...})) == bool 0`
- **Description:** This metric indicates whether all clusters are healthy. It provides a quick overview of the cluster state to ensure that there are no issues affecting service performance.

### CPU Throttled Seconds by Namespace
- **Metric:** `rate(container_cpu_cfs_throttled_seconds_total{namespace=~"$namespace"}[5m])`
- **Description:** This metric tracks the number of seconds during which CPU usage was throttled. Monitoring CPU throttling helps operators identify when services are exceeding their allocated CPU limits and may need optimization.

### Memory Usage by Pod Limits
- **Metric:** `100 * max(container_memory_working_set_bytes{namespace=~"$namespace"}
 / kube_pod_container_resource_limits{resource="memory"})`
- **Description:** This metric shows memory usage as a percentage of the memory limit set for each pod. It helps operators ensure that services are staying within their allocated memory limits to avoid performance degradation.

### CPU Usage by Pod Limits
- **Metric:** `100 * max(container_cpu_usage{namespace=~"$namespace"} / kube_pod_container_resource_limits{resource="cpu"})`
- **Description:** This metric displays CPU usage as a percentage of the CPU limit set for each pod. Monitoring CPU usage helps operators optimize service performance and prevent CPU exhaustion.

### Total Active Upstream Connections
- **Metric:** `sum(envoy_cluster_upstream_cx_active{app=~"$service"})`
- **Description:** This metric tracks the total number of active upstream connections to other services in the mesh. It provides insight into service dependencies and network load.

### Total Active Downstream Connections
- **Metric:** `sum(envoy_http_downstream_cx_active{app=~"$service"})`
- **Description:** This metric tracks the total number of active downstream connections from services to clients. It helps operators monitor service load and ensure that services are able to handle the traffic effectively.
