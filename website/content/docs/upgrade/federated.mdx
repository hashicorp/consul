---
layout: docs
page_title: Upgrade WAN-federated Consul datacenters
description: >-
  Upgrade your federated Consul datacenters without downtime and ensuring federation and ACL replication is mantained.
---

# Upgrade WAN-federated Consul datacenters

This page describes the process to upgrade multiple Consul datacenters that are deployed with WAN federation.

## Overview

One of the fundamental operations to be performed in any production environment is zero-downtime upgrade to a new version. 

Consul offers the opportunity of zero-downtime upgrade also for multi-datacenter federated Consul environments.

To upgrade your Consul datacenter's version, perform a rolling upgrade/restart of the Consul agents on all the servers nodes in the primary datacenter, followed by a similar rolling upgrade/restart of all the client agents. After the upgrade of the primary datacenter is completed successfully, perform the same process on the secondary datacenter. This approach ensures you maintain datacenters' availability and federation during the whole process.

## Prerequisites

### Consul versions

This page shows the use case of upgrading a federated Consul environment running on `1.19.2` to Consul `1.20.4`.

<Note>

As a general best practice, when upgrading, you should always consider upgrading to the latest available version to take advantage of all new features and fixes.

</Note>

To complete this tutorial, you need two wide area network (WAN) joined Consul datacenters with access control list (ACL) replication enabled. 

If you are starting from scratch, the follow documentation will help to set up your datacenters, or as a reference for your current configuration:

- [Deployment Guide](/consul/tutorials/production-deploy/deployment-guide)
- [Securing Consul with ACLs](/consul/docs/secure/acl)
- [Basic Federation with WAN Gossip](/consul/docs/east-west/wan-federation/vms)
- [ACL Replication for Multiple Datacenters](/consul/docs/secure/acl/token/federation)

Lastly, if you are using Consul service mesh, you should set [`enable_central_service_config = true`](/consul/docs/reference/agent/configuration-file/general#enable_central_service_config) on your Consul clients which will allow you to centrally configure the sidecar and mesh gateway proxies.

Verify your datacenters are successfully federated by using the `consul members -wan` command:

```shell-session
$ consul members -wan

Node                       Address           Status  Type    Build   Protocol  DC         Partition  Segment
consul-server-0.primary    172.20.0.10:8302  alive   server  1.19.2  2         primary    default    <all>
consul-server-1.primary    172.20.0.9:8302   alive   server  1.19.2  2         primary    default    <all>
consul-server-2.primary    172.20.0.14:8302  alive   server  1.19.2  2         primary    default    <all>
consul-server-0.secondary  172.20.0.5:8302   alive   server  1.19.2  2         secondary  default    <all>
consul-server-1.secondary  172.20.0.4:8302   alive   server  1.19.2  2         secondary  default    <all>
consul-server-2.secondary  172.20.0.8:8302   alive   server  1.19.2  2         secondary  default    <all>
```

## Prepare for upgrade

### Check version compatibility

The suggested upgrade path is to perform, at most, two major versions jumps (i.e., if `1.20.x` is the current release, do not use versions older than `1.19.x`). This helps avoiding risks during upgrades.

To verify if your upgrade path is safe check:

- [Upgrade Instructions](/consul/docs/upgrade/instructions)
- [Upgrading Specific Versions](/consul/docs/upgrade/version-specific)

### Take a snapshot

The procedure illustrated should not cause any data loss in Consul state. Still, as a general best practice, it is recommended to take a snapshot of your environment every time you perform a potentially disruptive operation such as an upgrade.

Follow instructions provided by [Backup a Consul datacenter](/consul/docs/manage/disaster-recovery/backup-restore#backup-a-consul-datacenter) to learn how to perform a snapshot on an existing Consul datacenter.

### Increase log verbosity on agents

To debug eventual issues with the upgrade process, temporarily modify your Consul server configuration so that their [log_level](/consul/docs/reference/agent/configuration-file/log#log_level) is set to `debug`. This will give you more information to work with in the event something goes wrong.

<CodeBlockConfig hideClipboard filename="consul.hcl" highlight="2">

```hcl
## ...
log_level = "debug"
## ...
```

</CodeBlockConfig>


Use the following command on your servers to reload the configuration.

```shell-session
$ consul reload

Configuration reload triggered
```

This change should be applied on all Consul nodes you are upgrading.

## Install new Consul version on agents

Follow instructions listed in [Install Consul](/consul/install) to install the last version of Consul on your agents.

## Server rolling upgrade

In order to minimize unavailability, perform the upgrade process one server at a time, starting with the followers and upgrading the Raft leader last.

To identify the Raft leader in your datacenter, use the `consul operator` command.

<CodeBlockConfig highlight="4">

```shell-session
$ consul operator raft list-peers

Node             ID                                    Address          State     Voter  RaftProtocol  Commit Index  Trails Leader By
consul-server-1  7eac8bf6-20dc-fd79-4a8e-a478d763d71a  172.20.0.4:8300  leader    true   3             214           -
consul-server-0  5b4cd28e-708c-0cea-4d5a-cbe534fce408  172.20.0.5:8300  follower  true   3             214           0 commits
consul-server-2  b87109a8-dd55-76ce-8cf4-123953daa62a  172.20.0.8:8300  follower  true   3             214           0 commits
```

</CodeBlockConfig>

In the example output above the leader is `consul-server-1` so you can proceed with upgrading `consul-server-0` and `consul-server-2` first and then upgrade `consul-server-1` last.

<Note>

The upgrade on the servers will be completed only after you complete the upgrade steps on **ALL** servers. 

</Note>

### Leave datacenter

Login to the server agent and issue the `consul leave` command.

```shell-session
$ consul leave

Graceful leave complete
```

Wait until the command returns.

After the server leaves the datacenter you should observe the following output in your datacenter.

<CodeBlockConfig highlight="4">

```shell-session
$ consul members

Node             Address           Status  Type    Build   Protocol  DC       Partition  Segment
consul-server-0  172.20.0.10:8301  left    server  1.19.2  2         primary  default    <all>
consul-server-1  172.20.0.9:8301   alive   server  1.19.2  2         primary  default    <all>
consul-server-2  172.20.0.14:8301  alive   server  1.19.2  2         primary  default    <all>
```

</CodeBlockConfig>

Confirm from the output the server is now shown as `left` in the command output.

### Start new Consul version

Before starting Consul, check the version for the binary in your path.

```shell-session
$ consul version

Consul v1.21.4
Revision 59b8b905
Build Date 2025-08-13T12:03:12Z
Protocol 2 spoken by default, understands 2 to 3 (agent will automatically use protocol >2 when speaking to compatible agents)
```

Start Consul using the new binary version. Confirm the node with the updated version joined the datacenter again.

<CodeBlockConfig highlight="4">

```shell-session
$ consul members

Node             Address           Status  Type    Build   Protocol  DC       Partition  Segment
consul-server-0  172.20.0.10:8301  alive   server  1.21.4  2         primary  default    <all>
consul-server-1  172.20.0.9:8301   alive   server  1.19.2  2         primary  default    <all>
consul-server-2  172.20.0.14:8301  alive   server  1.19.2  2         primary  default    <all>
```

</CodeBlockConfig>

As you can confirm, now all the three servers are marked as `alive` and now `consul-server-0` shows `1.19.2` as its version.

### Update ACL token for agent

In case your ACL configuration did not include `enable_token_persistence = true` and you did not set the server tokens in the configuration files, you will need to set the `agent` and `default` token for the agent again before it could join the datacenter.

Refer to [Apply individual tokens to agents](/consul/docs/secure/acl/bootstrap#apply-individual-tokens-to-agents) for detailed steps.

### Leader restart

It is important to perform the upgrade one server at a time to ensure there are enough alive servers to maintain quorum. 

Once enough servers with the new version join the raft cluster, it is possible that a new leader election will be triggered without the leading server leaving the datacenter or being restarted. If the process is followed, Consul will gracefully react to the leave and restart of the server agents and will remain available during the whole upgrade process.

<Note>

In this scenario each datacenter runs a total of 3 servers, meaning that you can maintain quorum as long as 2 servers are still part of the Raft cluster.

</Note>

## Client rolling upgrade

After the servers are correctly restarted and re-joined the datacenter you can perform the same steps on every client agent to upgrade Consul.

1. Install Consul's new version on the client
1. Stop the client agent using `consul leave`
1. Start Consul using the new binary
1. Verify the client is correcly shown in `consul members`

### Service downtime considerations

When upgrading the client agents, after you issue `consul leave` on the agent, the service provided by the agent will be marked as unhealthy and will not be discoverable until the Consul client agent is restarted.

To avoid downtime for your services you should consider, as a general best practice, to run multiple instance of the same service each with its own Consul client agent.

In this way you can upgrade the two Consul agents in two separate moments and Consul will automatically redirect traffic to the other service instances during the Consul agent upgrade.

### Envoy version compatibility

If you are using the Consul service mesh functionality, when upgrading Consul on the client nodes you will also have to make sure the Envoy version you have on the node is compatible with the new version of Consul.

You can check out the Envoy version supported by your new Consul version on the [Envoy Integration](/consul/docs/connect/proxies/envoy#supported-versions)
documentation page.

<Tip>

If you are using Consul `1.8.4` or later you can also use the [`/v1/agent/self`](/consul/api-docs/agent#read-configuration) API endpoint to check the compatible Envoy version for your running agent.

</Tip>

In this scenario we are upgradring from Consul `1.12.2`, which supports Envoy up to version `1.33.x` to Consul `1.21.4` that supports Envoy from version `1.31.x`.

This means that, the two version share a compatible Envoy version and that if you are running Envoy `1.33.x` on your agents you might not need to upgrade Envoy right away.

We recommend to upgrade Envoy to the latest supported version to leverage the Consul compatibility with the new Envoy functionalities and improvements.

Refer to [Envoy documentation](https://www.envoyproxy.io/docs/envoy/latest/start/install) to learn how to install Envoy on your system.

## Update Secondary Datacenter

Once the upgrade for the primary datacenter is completed you can follow the same steps to perform the upgrade on the second datacenter.

## Verify federation

After the upgrade process is complete you can confirm federation is still working using the `consul members` command.

```shell-session
$ consul members -wan

Node                       Address           Status  Type    Build   Protocol  DC         Partition  Segment
consul-server-0.primary    172.20.0.10:8302  alive   server  1.21.4  2         primary    default    <all>
consul-server-1.primary    172.20.0.9:8302   alive   server  1.21.4  2         primary    default    <all>
consul-server-2.primary    172.20.0.14:8302  alive   server  1.21.4  2         primary    default    <all>
consul-server-0.secondary  172.20.0.5:8302   alive   server  1.21.4  2         secondary  default    <all>
consul-server-1.secondary  172.20.0.4:8302   alive   server  1.21.4  2         secondary  default    <all>
consul-server-2.secondary  172.20.0.8:8302   alive   server  1.21.4  2         secondary  default    <all>
```

Also you can check replication is still active in the secondary datacenter using the [`/v1/acl/replication`](/consul/api-docs/acl#check-acl-replication) REST endpoint on any Consul agent on the secondary datacenter.  The command in the example uses one of the secondary datacenter servers.

```shell-session
$ curl -s -H "X-Consul-Token: $CONSUL_HTTP_TOKEN" https://consul-server-0.secondary/v1/acl/replication?pretty

{
    "Enabled": true,
    "Running": true,
    "SourceDatacenter": "primary",
    "ReplicationType": "tokens",
    "ReplicatedIndex": 627,
    "ReplicatedRoleIndex": 1,
    "ReplicatedTokenIndex": 631,
    "LastSuccess": "2025-09-15T17:16:28Z",
    "LastError": "0001-01-01T00:00:00Z"
}
```

<Note>

The primary datacenter, indicated by `primary_datacenter` in the secondary server configuration, will always show as having replication disabled, so this is normal even if replication is happening.

</Note>

## Next steps

The process described in this tutorial can be safely applied to your production datacenter without the risk of downtime. We still recommend you to test any possible disruptive operation such as an upgrade, on a test environment that replicates the existing production environment.

To simplify the upgrade process, Enterprise users can leverage [Automated Upgrades](/consul/docs/upgrade/automated) feature of Consul's autopilot.